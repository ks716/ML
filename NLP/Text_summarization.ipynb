{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Sree_M17_Assignment.ipynb","provenance":[{"file_id":"1ZzRrhjEXCKTVpGfL9ZlNa6aSU6xTPLYD","timestamp":1619535423868}],"collapsed_sections":[],"toc_visible":true},"coursera":{"schema_names":["NLPC4-2"]},"jupytext":{"encoding":"# -*- coding: utf-8 -*-","formats":"ipynb,py:percent"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b4dcf5636bf6433cb1c53d368dad30ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ede6c315db9485084ab1c853a3f4f27","IPY_MODEL_bbd97cd73c00490b880c4d27bd07ce0b"],"layout":"IPY_MODEL_2d1b428567a1400385535974aacc9eb7"}},"9ede6c315db9485084ab1c853a3f4f27":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Dl Completed...: 100%","description_tooltip":null,"layout":"IPY_MODEL_c606061717154c329bf12f8daaeba836","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7607f82da0e47009de8e229d1dd8fff","value":1}},"bbd97cd73c00490b880c4d27bd07ce0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2a326596d8e47f6b868e59921b96925","placeholder":"​","style":"IPY_MODEL_af1999a625264816a4f8ec5248a89ec4","value":" 5/5 [02:07&lt;00:00, 25.46s/ url]"}},"2d1b428567a1400385535974aacc9eb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c606061717154c329bf12f8daaeba836":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7607f82da0e47009de8e229d1dd8fff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"b2a326596d8e47f6b868e59921b96925":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af1999a625264816a4f8ec5248a89ec4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3309c55621cf4498ab1f12cc436f4bee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a348dd77f5749959124e78e620989a3","IPY_MODEL_0431cf891d49437ca16d078259e38f31"],"layout":"IPY_MODEL_0c2e6384b3e94085a86015caf66df46b"}},"5a348dd77f5749959124e78e620989a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Dl Size...: ","description_tooltip":null,"layout":"IPY_MODEL_d3850ccf97154e8cad11993b7911f37b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df5ffc14bc8244debb7cdd4b483cc547","value":1}},"0431cf891d49437ca16d078259e38f31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_709c84dab9974d43b5f7bd39d07183df","placeholder":"​","style":"IPY_MODEL_aa5622d82e8244be9ca03a37ccfb33f6","value":" 557/? [02:07&lt;00:00,  4.38 MiB/s]"}},"0c2e6384b3e94085a86015caf66df46b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3850ccf97154e8cad11993b7911f37b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df5ffc14bc8244debb7cdd4b483cc547":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"709c84dab9974d43b5f7bd39d07183df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa5622d82e8244be9ca03a37ccfb33f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65b28482baa44fb2a1a073e7b7b0a680":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46697f120e894993a813299512ef4e89","IPY_MODEL_eb0f607cd6854b2fb441fa9ad4f5a57a"],"layout":"IPY_MODEL_5cedad3ea207463baecdbb0e87b0b8a4"}},"46697f120e894993a813299512ef4e89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Extraction completed...: 100%","description_tooltip":null,"layout":"IPY_MODEL_8bf6f596e61f40d5ae67dbc295435624","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_97328bbeaaf540b6ad56871389a5e097","value":1}},"eb0f607cd6854b2fb441fa9ad4f5a57a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70c87ef703b841119db70d543c9b4079","placeholder":"​","style":"IPY_MODEL_0284e5ebd3164a808f3de3c340522b33","value":" 2/2 [02:07&lt;00:00, 63.58s/ file]"}},"5cedad3ea207463baecdbb0e87b0b8a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bf6f596e61f40d5ae67dbc295435624":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97328bbeaaf540b6ad56871389a5e097":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"70c87ef703b841119db70d543c9b4079":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0284e5ebd3164a808f3de3c340522b33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fad75f3d793f493f9f2f80059da872ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17ab6ce8f61b45dc8ffcb5565b35e569","IPY_MODEL_de3e3427d102438c83144d413e0ec077"],"layout":"IPY_MODEL_e4d51f0e944b4df3967915f21a308c3f"}},"17ab6ce8f61b45dc8ffcb5565b35e569":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Generating splits...: 100%","description_tooltip":null,"layout":"IPY_MODEL_f227574d12c64ad7ae27a5b4080cf83a","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca7bac8e7a394fd58a2c12032e224c66","value":3}},"de3e3427d102438c83144d413e0ec077":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c1d0475d33141c9a57f1f16719b98b9","placeholder":"​","style":"IPY_MODEL_e27910deb3944cf7a7d832eb436dc7fa","value":" 3/3 [04:44&lt;00:00, 134.31s/ splits]"}},"e4d51f0e944b4df3967915f21a308c3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f227574d12c64ad7ae27a5b4080cf83a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca7bac8e7a394fd58a2c12032e224c66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"4c1d0475d33141c9a57f1f16719b98b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e27910deb3944cf7a7d832eb436dc7fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"799eca91ad5045feb3f932a4d7c7464e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09bf3261c689442c937633519c291ae4","IPY_MODEL_5661cf4757c24fdb919ee56dcaea4a74"],"layout":"IPY_MODEL_ea4dcaee9ee842fc84c47d9f498cbbc2"}},"09bf3261c689442c937633519c291ae4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Generating train examples...: 100%","description_tooltip":null,"layout":"IPY_MODEL_32f2eb95d9964da8b096c278f374e4b1","max":287113,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52b90f6875304294a0c883475ff18628","value":287113}},"5661cf4757c24fdb919ee56dcaea4a74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_961b3dc0abbb46b388447096680d4d86","placeholder":"​","style":"IPY_MODEL_9acb6b9dc695493f9ce98ee8659b1ef4","value":" 287113/287113 [04:14&lt;00:00, 1062.74 examples/s]"}},"ea4dcaee9ee842fc84c47d9f498cbbc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32f2eb95d9964da8b096c278f374e4b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52b90f6875304294a0c883475ff18628":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"961b3dc0abbb46b388447096680d4d86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9acb6b9dc695493f9ce98ee8659b1ef4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fec790c458d8456bbb24c91e972a9205":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e558a303f37443149b79d8a7dcd9162a","IPY_MODEL_bfe3f6d0384444fcbeaf8e73204e26a0"],"layout":"IPY_MODEL_efe089baa1c54e0cab81ccfe4ed5af5c"}},"e558a303f37443149b79d8a7dcd9162a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Shuffling cnn_dailymail-train.tfrecord...: 100%","description_tooltip":null,"layout":"IPY_MODEL_e88a83d39ce848af837580d40afd70ee","max":287113,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c587c28a272849d8a926a49078daa95e","value":287113}},"bfe3f6d0384444fcbeaf8e73204e26a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69490b6a17134d94873c705c1b64351c","placeholder":"​","style":"IPY_MODEL_8d68126071874bc2b45efc6bc93dcb5d","value":" 287113/287113 [00:08&lt;00:00, 37096.35 examples/s]"}},"efe089baa1c54e0cab81ccfe4ed5af5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e88a83d39ce848af837580d40afd70ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c587c28a272849d8a926a49078daa95e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"69490b6a17134d94873c705c1b64351c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d68126071874bc2b45efc6bc93dcb5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d170697cda948919ec8bac01111d63d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_560f0938991642608d17a8edb844de98","IPY_MODEL_0b5947ea99454f38b6bbc40d22486b94"],"layout":"IPY_MODEL_38300f2de9024cdbba07792f0621149e"}},"560f0938991642608d17a8edb844de98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Generating validation examples...: 100%","description_tooltip":null,"layout":"IPY_MODEL_f8e77dff950e46e4b39754b524fd5eab","max":13368,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9672f632a624bf2afec920ce54fd7be","value":13368}},"0b5947ea99454f38b6bbc40d22486b94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b3aad5df90e439699ea3ee1baafe0ee","placeholder":"​","style":"IPY_MODEL_55f3fbee55164c798a2245e92853dfc5","value":" 13368/13368 [00:11&lt;00:00, 1186.23 examples/s]"}},"38300f2de9024cdbba07792f0621149e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e77dff950e46e4b39754b524fd5eab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9672f632a624bf2afec920ce54fd7be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"8b3aad5df90e439699ea3ee1baafe0ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55f3fbee55164c798a2245e92853dfc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f2f60d5a9a24d41bca7db10e52f0209":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b88941b8f6ac4db989c68823757ef45d","IPY_MODEL_e4ae337a7c7a4890b057fc07510d3213"],"layout":"IPY_MODEL_cdfa66d664844f05a1033f00d789a37c"}},"b88941b8f6ac4db989c68823757ef45d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Shuffling cnn_dailymail-validation.tfrecord...: 100%","description_tooltip":null,"layout":"IPY_MODEL_57d82e48c470444b89d4fbfe10370c3a","max":13368,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6b3ffbaacc345d5b9d2b1f613ca76a5","value":13368}},"e4ae337a7c7a4890b057fc07510d3213":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86a54d5aa23e4daa9b0f2ea2ac9f6b33","placeholder":"​","style":"IPY_MODEL_935a7cb7aa394e13a22b7fc01278f378","value":" 13368/13368 [00:00&lt;00:00, 25473.16 examples/s]"}},"cdfa66d664844f05a1033f00d789a37c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57d82e48c470444b89d4fbfe10370c3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b3ffbaacc345d5b9d2b1f613ca76a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"86a54d5aa23e4daa9b0f2ea2ac9f6b33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"935a7cb7aa394e13a22b7fc01278f378":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"206f840330e74dd0930463b80900818b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7437d1fd673458da76d515627686d4e","IPY_MODEL_db66036173e34861821b18c8bce5c343"],"layout":"IPY_MODEL_0291cb36d39442588bffde25bf35daba"}},"b7437d1fd673458da76d515627686d4e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Generating test examples...: 100%","description_tooltip":null,"layout":"IPY_MODEL_368a9a59bcf74a46b76ec0742c6ccdee","max":11490,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f67bbfd2f344119b4d20d1ed3abcae0","value":11490}},"db66036173e34861821b18c8bce5c343":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc2d590e13fb4c6986e4717905c4dbe3","placeholder":"​","style":"IPY_MODEL_93c1ee39bed3421e99d464cf08a72752","value":" 11490/11490 [00:09&lt;00:00, 1197.10 examples/s]"}},"0291cb36d39442588bffde25bf35daba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"368a9a59bcf74a46b76ec0742c6ccdee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f67bbfd2f344119b4d20d1ed3abcae0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"dc2d590e13fb4c6986e4717905c4dbe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93c1ee39bed3421e99d464cf08a72752":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf88dcd13ccf445eabef7e352165a41a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_37e8034b8cf24603b5eba865bfdcb7b9","IPY_MODEL_977fcfa64ddf4e478451b91fa6ccf273"],"layout":"IPY_MODEL_1b525c9238cf4a558e6c234b475a6f0e"}},"37e8034b8cf24603b5eba865bfdcb7b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"Shuffling cnn_dailymail-test.tfrecord...: 100%","description_tooltip":null,"layout":"IPY_MODEL_81c69945d4344bacbd05017ef8501fe0","max":11490,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06a8a629de6144bf8fd6f43cdc7df9eb","value":11490}},"977fcfa64ddf4e478451b91fa6ccf273":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40bcfb5fca3447e58f309b8255b89623","placeholder":"​","style":"IPY_MODEL_b8773f6f44e3486ba0acce249961ffb2","value":" 11490/11490 [00:00&lt;00:00, 28708.52 examples/s]"}},"1b525c9238cf4a558e6c234b475a6f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81c69945d4344bacbd05017ef8501fe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06a8a629de6144bf8fd6f43cdc7df9eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"40bcfb5fca3447e58f309b8255b89623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8773f6f44e3486ba0acce249961ffb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"7yuytuIllsv1"},"source":["\n","# Transformer Summarizer\n","\n","In this assignment you will explore summarization using the transformer model. \n","<img src = \"https://drive.google.com/file/d/1tL_413rCWwX9v5SIaPvZQ2UvT4MCSG5D/view?usp=sharing\">\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4-3lxSnXRWPx"},"source":["## Outline\n","\n","- [Introduction](#0)\n","- [Part 1: Importing the dataset](#1)\n","    - [1.1 Encode & Decode helper functions](#1.1)\n","    - [1.2 Defining parameters](#1.2)\n","    - [1.3 Exploring the data](#1.3)\n","- [Part 2: Summarization with transformer](#2)\n","    - [2.1 Dot product attention](#2.1)\n","        - [Exercise 01](#ex01)\n","    - [2.2 Causal Attention](#2.2)\n","        - [Exercise 02](#ex02)\n","    - [2.3 Transformer decoder block](#2.3)\n","        - [Exercise 03](#ex03)\n","    - [2.4 Transformer Language model](#2.4)\n","        - [Exercise 04](#ex04)\n","- [Part 3: Training](#3)\n","    - [3.1 Training the model](#3.1)\n","        - [Exercise 05](#ex05)\n","- [Part 4: Evaluation](#4)\n","    - [4.1 Loading in a trained model](#4.1)\n","- [Part 5: Testing with your own input](#5) \n","    - [Exercise 6](#ex06)\n","    - [5.1 Greedy decoding](#5.1)\n","        - [Exercise 07](#ex07)"]},{"cell_type":"markdown","metadata":{"id":"H4NlfEQhRWPy"},"source":["<a name='0'></a>\n","### Introduction\n","\n","Summarization is an important task in natural language processing and could be useful for a consumer enterprise. For example, bots can be used to scrape articles, summarize them, and then you can use sentiment analysis to identify the sentiment about certain stocks. Anyways who wants to read an article or a long email today, when you can build a transformer to summarize text for you. \n","\n","By completing this assignment you will learn to:  \n","\n","- Use built-in functions to preprocess your data\n","- Implement DotProductAttention\n","- Implement Causal Attention\n","- Understand how attention works\n","- Build the transformer model\n","- Evaluate your model\n","- Summarize an article\n","\n","As you can tell, this model is slightly different than the ones you have already implemented. This is heavily based on attention and does not rely on sequences, which allows for parallel computing. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CChWzW-rEHVb","executionInfo":{"elapsed":42330,"status":"ok","timestamp":1619797173856,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"8a32d04d-92f1-40b4-f688-47bc08e6601b"},"source":["import sys\n","import os\n","\n","import numpy as np\n","\n","import textwrap\n","wrapper = textwrap.TextWrapper(width=70)\n","\n","!pip install trax==1.3.7\n","import trax\n","from trax import layers as tl\n","from trax.fastmath import numpy as jnp\n","\n","# to print the entire np array\n","np.set_printoptions(threshold=sys.maxsize)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting trax==1.3.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/51/305b839f51d53abb393777f743e497d27bb341478f3fdec4d6ddaccc9fb5/trax-1.3.7-py2.py3-none-any.whl (521kB)\n","\u001b[K     |████████████████████████████████| 522kB 5.9MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from trax==1.3.7) (4.0.1)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from trax==1.3.7) (0.12.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from trax==1.3.7) (1.4.1)\n","Collecting t5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/e4/e2dc66207464795aafecc5c8cef9a35b5c9a61b974ac60a2c306c12bfd4c/t5-0.9.1-py3-none-any.whl (152kB)\n","\u001b[K     |████████████████████████████████| 153kB 33.2MB/s \n","\u001b[?25hRequirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from trax==1.3.7) (0.1.65+cuda110)\n","Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from trax==1.3.7) (0.2.12)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from trax==1.3.7) (5.4.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from trax==1.3.7) (1.15.0)\n","Collecting funcsigs\n","  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trax==1.3.7) (1.19.5)\n","Collecting tensorflow-text\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/c0/c0fed4301f592c3b56638ae7292612c17d91a43891ba1aaf9636d535beae/tensorflow_text-2.4.3-cp37-cp37m-manylinux1_x86_64.whl (3.4MB)\n","\u001b[K     |████████████████████████████████| 3.4MB 33.3MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from trax==1.3.7) (0.4.0)\n","Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from trax==1.3.7) (0.17.3)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (0.29.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (0.1.6)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (20.3.0)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (5.1.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (0.3.3)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (3.12.4)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (1.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (4.41.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (0.16.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax==1.3.7) (2.23.0)\n","Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5->trax==1.3.7) (2.9.0)\n","Collecting tfds-nightly\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/87/94d83e57c5b32920a2975697499a416fd7567001870acdac14cec1989eb2/tfds_nightly-4.2.0.dev202104300107-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.9MB 37.7MB/s \n","\u001b[?25hCollecting transformers>=2.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 39.9MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from t5->trax==1.3.7) (0.22.2.post1)\n","Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.5MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from t5->trax==1.3.7) (1.1.5)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 37.3MB/s \n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5->trax==1.3.7) (3.2.5)\n","Collecting rouge-score\n","  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n","Collecting seqio\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/21/8161f170208b4da94036aa74c6974caaeca82a9a634e80bf98e1a0cd6e10/seqio-0.0.3-py3-none-any.whl (241kB)\n","\u001b[K     |████████████████████████████████| 245kB 34.8MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5->trax==1.3.7) (1.8.1+cu101)\n","Collecting mesh-tensorflow[transformer]>=0.1.13\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/10/37df0bc87ebf84e1414613176340e3aadc3697d2bd112bf63d3d4b1e848a/mesh_tensorflow-0.1.19-py3-none-any.whl (366kB)\n","\u001b[K     |████████████████████████████████| 368kB 25.7MB/s \n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib->trax==1.3.7) (1.12)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax->trax==1.3.7) (3.3.0)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->trax==1.3.7) (0.12.0)\n","Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->trax==1.3.7) (2.4.1)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->trax==1.3.7) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->trax==1.3.7) (1.3.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->trax==1.3.7) (1.53.0)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->trax==1.3.7) (3.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->trax==1.3.7) (56.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.7) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.7) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.7) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax==1.3.7) (1.24.3)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->t5->trax==1.3.7) (2018.9)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5->trax==1.3.7) (3.7.4.3)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 38.9MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax==1.3.7) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax==1.3.7) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 39.8MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax==1.3.7) (3.10.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax==1.3.7) (3.0.12)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->t5->trax==1.3.7) (1.0.1)\n","Collecting portalocker==2.0.0\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->t5->trax==1.3.7) (2.8.1)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (1.32.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (1.1.2)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (2.10.0)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (2.4.1)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (0.36.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (1.12.1)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (0.3.3)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (1.6.3)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (2.4.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (0.2.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.7.0->t5->trax==1.3.7) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5->trax==1.3.7) (7.1.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (0.4.4)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (1.28.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (3.3.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (1.8.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (4.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (4.7.2)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax==1.3.7) (0.4.8)\n","Installing collected packages: tfds-nightly, tokenizers, sacremoses, transformers, portalocker, sacrebleu, sentencepiece, tensorflow-text, rouge-score, seqio, mesh-tensorflow, t5, funcsigs, trax\n","Successfully installed funcsigs-1.0.2 mesh-tensorflow-0.1.19 portalocker-2.0.0 rouge-score-0.0.4 sacrebleu-1.5.1 sacremoses-0.0.45 sentencepiece-0.1.95 seqio-0.0.3 t5-0.9.1 tensorflow-text-2.4.3 tfds-nightly-4.2.0.dev202104300107 tokenizers-0.10.2 transformers-4.5.1 trax-1.3.7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kEL2rvaHRWP4"},"source":["<a name='1'></a>\n","## Part 1: Importing the dataset"]},{"cell_type":"markdown","metadata":{"id":"Tz2CfXogokka"},"source":["Trax makes it easy to work with Tensorflow's datasets:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197,"referenced_widgets":["b4dcf5636bf6433cb1c53d368dad30ba","9ede6c315db9485084ab1c853a3f4f27","bbd97cd73c00490b880c4d27bd07ce0b","2d1b428567a1400385535974aacc9eb7","c606061717154c329bf12f8daaeba836","a7607f82da0e47009de8e229d1dd8fff","b2a326596d8e47f6b868e59921b96925","af1999a625264816a4f8ec5248a89ec4","3309c55621cf4498ab1f12cc436f4bee","5a348dd77f5749959124e78e620989a3","0431cf891d49437ca16d078259e38f31","0c2e6384b3e94085a86015caf66df46b","d3850ccf97154e8cad11993b7911f37b","df5ffc14bc8244debb7cdd4b483cc547","709c84dab9974d43b5f7bd39d07183df","aa5622d82e8244be9ca03a37ccfb33f6","65b28482baa44fb2a1a073e7b7b0a680","46697f120e894993a813299512ef4e89","eb0f607cd6854b2fb441fa9ad4f5a57a","5cedad3ea207463baecdbb0e87b0b8a4","8bf6f596e61f40d5ae67dbc295435624","97328bbeaaf540b6ad56871389a5e097","70c87ef703b841119db70d543c9b4079","0284e5ebd3164a808f3de3c340522b33","fad75f3d793f493f9f2f80059da872ba","17ab6ce8f61b45dc8ffcb5565b35e569","de3e3427d102438c83144d413e0ec077","e4d51f0e944b4df3967915f21a308c3f","f227574d12c64ad7ae27a5b4080cf83a","ca7bac8e7a394fd58a2c12032e224c66","4c1d0475d33141c9a57f1f16719b98b9","e27910deb3944cf7a7d832eb436dc7fa","799eca91ad5045feb3f932a4d7c7464e","09bf3261c689442c937633519c291ae4","5661cf4757c24fdb919ee56dcaea4a74","ea4dcaee9ee842fc84c47d9f498cbbc2","32f2eb95d9964da8b096c278f374e4b1","52b90f6875304294a0c883475ff18628","961b3dc0abbb46b388447096680d4d86","9acb6b9dc695493f9ce98ee8659b1ef4","fec790c458d8456bbb24c91e972a9205","e558a303f37443149b79d8a7dcd9162a","bfe3f6d0384444fcbeaf8e73204e26a0","efe089baa1c54e0cab81ccfe4ed5af5c","e88a83d39ce848af837580d40afd70ee","c587c28a272849d8a926a49078daa95e","69490b6a17134d94873c705c1b64351c","8d68126071874bc2b45efc6bc93dcb5d","7d170697cda948919ec8bac01111d63d","560f0938991642608d17a8edb844de98","0b5947ea99454f38b6bbc40d22486b94","38300f2de9024cdbba07792f0621149e","f8e77dff950e46e4b39754b524fd5eab","c9672f632a624bf2afec920ce54fd7be","8b3aad5df90e439699ea3ee1baafe0ee","55f3fbee55164c798a2245e92853dfc5","2f2f60d5a9a24d41bca7db10e52f0209","b88941b8f6ac4db989c68823757ef45d","e4ae337a7c7a4890b057fc07510d3213","cdfa66d664844f05a1033f00d789a37c","57d82e48c470444b89d4fbfe10370c3a","c6b3ffbaacc345d5b9d2b1f613ca76a5","86a54d5aa23e4daa9b0f2ea2ac9f6b33","935a7cb7aa394e13a22b7fc01278f378","206f840330e74dd0930463b80900818b","b7437d1fd673458da76d515627686d4e","db66036173e34861821b18c8bce5c343","0291cb36d39442588bffde25bf35daba","368a9a59bcf74a46b76ec0742c6ccdee","3f67bbfd2f344119b4d20d1ed3abcae0","dc2d590e13fb4c6986e4717905c4dbe3","93c1ee39bed3421e99d464cf08a72752","cf88dcd13ccf445eabef7e352165a41a","37e8034b8cf24603b5eba865bfdcb7b9","977fcfa64ddf4e478451b91fa6ccf273","1b525c9238cf4a558e6c234b475a6f0e","81c69945d4344bacbd05017ef8501fe0","06a8a629de6144bf8fd6f43cdc7df9eb","40bcfb5fca3447e58f309b8255b89623","b8773f6f44e3486ba0acce249961ffb2"]},"id":"VInmKSkhEhle","executionInfo":{"elapsed":467640,"status":"ok","timestamp":1619797599179,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"dd6f45c7-855a-446e-92fd-b92c222c8cd8"},"source":["# This will download the dataset if no data_dir is specified.\n","# Downloading and processing can take bit of time,\n","# so we have the data already in 'data/' for you\n","\n","# Importing CNN/DailyMail articles dataset\n","train_stream_fn = trax.data.TFDS('cnn_dailymail',\n","                                 data_dir='data/',\n","                                 keys=('article', 'highlights'),\n","                                 train=True)\n","\n","# This should be much faster as the data is downloaded already.\n","eval_stream_fn = trax.data.TFDS('cnn_dailymail',\n","                                data_dir='data/',\n","                                keys=('article', 'highlights'),\n","                                train=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1mDownloading and preparing dataset 558.32 MiB (download: 558.32 MiB, generated: 1.27 GiB, total: 1.82 GiB) to data/cnn_dailymail/3.1.0...\u001b[0m\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4dcf5636bf6433cb1c53d368dad30ba","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3309c55621cf4498ab1f12cc436f4bee","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65b28482baa44fb2a1a073e7b7b0a680","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fad75f3d793f493f9f2f80059da872ba","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Generating splits...', max=3.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"799eca91ad5045feb3f932a4d7c7464e","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Generating train examples...', max=287113.0, style=Progre…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fec790c458d8456bbb24c91e972a9205","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Shuffling cnn_dailymail-train.tfrecord...', max=287113.0,…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d170697cda948919ec8bac01111d63d","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Generating validation examples...', max=13368.0, style=Pr…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f2f60d5a9a24d41bca7db10e52f0209","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Shuffling cnn_dailymail-validation.tfrecord...', max=1336…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"206f840330e74dd0930463b80900818b","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Generating test examples...', max=11490.0, style=Progress…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf88dcd13ccf445eabef7e352165a41a","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Shuffling cnn_dailymail-test.tfrecord...', max=11490.0, s…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\u001b[1mDataset cnn_dailymail downloaded and prepared to data/cnn_dailymail/3.1.0. Subsequent calls will reuse this data.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"suxxQ-AWokka"},"source":["<a name='1.1'></a>\n","## 1.1 Tokenize & Detokenize helper functions\n","\n","Just like in the previous assignment, the cell above loads in the encoder for you. Given any data set, you have to be able to map words to their indices, and indices to their words. The inputs and outputs to your [Trax](https://github.com/google/trax) models are usually tensors of numbers where each number corresponds to a word. If you were to process your data manually, you would have to make use of the following: \n","\n","- <span style='color:blue'> word2Ind: </span> a dictionary mapping the word to its index.\n","- <span style='color:blue'> ind2Word:</span> a dictionary mapping the index to its word.\n","- <span style='color:blue'> word2Count:</span> a dictionary mapping the word to the number of times it appears. \n","- <span style='color:blue'> num_words:</span> total number of words that have appeared. \n","\n","The vocabulary file can be found at https://drive.google.com/drive/folders/1FZWPjBUoeQVAatON9wkZg4r5CZeGSMpW?usp=sharing. Create a new `vocab` folder in your colab environment and upload the vocabulary file downloaded from the link to it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CutW3aJY2kdG","executionInfo":{"elapsed":518774,"status":"ok","timestamp":1619797650322,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"524f42b0-cd40-494e-bf06-965144e0969c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f0UQ7II_5ymF"},"source":["!mkdir vocab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dz4fgt_F292V"},"source":["!cp '/content/drive/MyDrive/data/m17/summarize32k.subword.subwords' '/content/vocab/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"djTiSLcaNFGa"},"source":["def tokenize(input_str, EOS=1):\n","    \"\"\"Input str to features dict, ready for inference\"\"\"\n","  \n","    # Use the trax.data.tokenize method. It takes streams and returns streams,\n","    # we get around it by making a 1-element stream with `iter`.\n","    inputs =  next(trax.data.tokenize(iter([input_str]),\n","                                      vocab_dir='vocab/',\n","                                      vocab_file='summarize32k.subword.subwords'))\n","    \n","    # Mark the end of the sentence with EOS\n","    return list(inputs) + [EOS]\n","\n","def detokenize(integers):\n","    \"\"\"List of ints to str\"\"\"\n","  \n","    s = trax.data.detokenize(integers,\n","                             vocab_dir='vocab/',\n","                             vocab_file='summarize32k.subword.subwords')\n","    \n","    return wrapper.fill(s)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7WvhaFbCRWQS"},"source":["<a name='1.2'></a>\n","\n","## 1.2 Preprocessing for Language Models: Concatenate It!\n","\n","This assignmeny uses a language model -- Transformer Decoder -- to solve\n","an input-output problem. As you know, language models only predict the next\n","word, they have no notion of inputs. To create a single input suitable for\n","a language model, we concatenate inputs with targets putting a separator\n","in between. We also need to create a mask -- with 0s at inputs and 1s at targets -- so that the model is not penalized for mis-predicting the article and only focuses on the summary. See the preprocess function below for how this is done."]},{"cell_type":"code","metadata":{"id":"c4rgPxYSRWQS"},"source":["# Special tokens\n","SEP = 0 # Padding or separator token\n","EOS = 1 # End of sentence token\n","\n","# Concatenate tokenized inputs and targets using 0 as separator.\n","def preprocess(stream):\n","    for (article, summary) in stream:\n","        joint = np.array(list(article) + [EOS, SEP] + list(summary) + [EOS])\n","        mask = [0] * (len(list(article)) + 2) + [1] * (len(list(summary)) + 1) # Accounting for EOS and SEP\n","        yield joint, joint, np.array(mask)\n","\n","# You can combine a few data preprocessing steps into a pipeline like this.\n","input_pipeline = trax.data.Serial(\n","    # Tokenizes\n","    trax.data.Tokenize(vocab_dir='vocab/',\n","                       vocab_file='summarize32k.subword.subwords'),\n","    # Uses function defined above\n","    preprocess,\n","    # Filters out examples longer than 2048\n","    trax.data.FilterByLength(2048)\n",")\n","\n","# Apply preprocessing to data streams.\n","train_stream = input_pipeline(train_stream_fn())\n","eval_stream = input_pipeline(eval_stream_fn())\n","\n","train_input, train_target, train_mask = next(train_stream)\n","\n","assert sum((train_input - train_target)**2) == 0  # They are the same in Language Model (LM)."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKFoGsUKSa_I","executionInfo":{"elapsed":521666,"status":"ok","timestamp":1619797653235,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"c70f8c30-067d-4951-ddf4-179de29a5a92"},"source":["# prints mask, 0s on article, 1s on summary\n","print(f'Single example mask:\\n\\n {train_mask}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Single example mask:\n","\n"," [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S4uHyCkbSuUo","executionInfo":{"elapsed":521656,"status":"ok","timestamp":1619797653236,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"543f2119-9a81-4731-d490-15bd5fb733a3"},"source":["# prints: [Example][<EOS>][<pad>][Example Summary][<EOS>]\n","print(f'Single example:\\n\\n {detokenize(train_input)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Single example:\n","\n"," Another suspected suicide bombing struck the southern Russian city of\n","Volgograd on Monday, killing at least 14 people and further\n","highlighting Russia's security challenges as it prepares to host the\n","Winter Olympics in less than six weeks. The explosion hit a trolleybus\n","near a busy market during the morning rush hour, a day after a blast\n","at Volgograd's main train station killed 17 people and wounded at\n","least 35. Vladmir Markin, a spokesman for the country's federal\n","investigation agency, told the state-run news agency RIA Novosti that\n","both explosions were terrorist attacks. \"This strike, which was\n","cynically planned for the period of preparations for New Year's\n","celebrations, is one more attempt by terrorists to open a domestic\n","front, sow panic and chaos, and trigger religious strife and conflicts\n","in Russian society,\" said a statement Monday by Russia's Foreign\n","Affairs Ministry. \"We will not back down and will continue our tough\n","and consistent offensive\" against terrorists, the ministry's statement\n","said, adding that such an enemy \"can only be stopped by joint efforts\"\n","involving the international community. The approaching Olympics . No\n","one claimed responsibility for the Volgograd blasts, but they occurred\n","several months after the leader of a Chechen separatist group pledged\n","violence to disrupt the 2014 Sochi Winter Olympics that begin on\n","February 7. International Olympic Committee President Thomas Bach\n","condemned the bombings as \"a despicable attack on innocent people.\n","\"The entire international movement joins me in utterly condemning this\n","cowardly act,\" Bach said in a statement, adding that he wrote Russian\n","President Vladimir Putin to express condolences as well as \"our\n","confidence in the Russian authorities to deliver safe and secure Games\n","in Sochi.\" Meanwhile, the United States offered its \"full support to\n","the Russian government in security preparations for the Sochi Olympic\n","Games,\" National Security Council spokeswoman Caitlin Hayden said in a\n","statement. \"We would welcome the opportunity for closer cooperation\n","for the safety of the athletes, spectators, and other participants,\"\n","Hayden said. Volgograd is a major rail hub in southern Russia and a\n","main transit point for people traveling by train to Sochi on the Black\n","Sea, just over 400 miles (645 kilometers) to the southwest. Each day,\n","thousands of passengers use the station in the city once called\n","Stalingrad. Two blasts in two days . Video footage from the scene\n","Monday showed the twisted shell of a blue trolleybus, with debris\n","spread around it. The impact of the blast blew out the roof of the\n","bus, as well as windows of several nearby houses. At least 28 people\n","were reported to be wounded, with several in serious condition,\n","including one 6-month-old child, RIA Novosti reported. Based on the\n","footage, the blast appeared to have occurred in the back half of the\n","bus. The federal investigation agency said it believes the explosion\n","was set off by a male suicide bomber. Investigators said the train\n","station blast Sunday also appeared to have been caused by a suicide\n","bomber. Markin told RIA Novosti that DNA testing will be carried out\n","on the remains of the station bomber, who used the equivalent of 22\n","pounds (10 kilograms) of TNT in a device containing shrapnel.\n","Investigators said they also found an unexploded grenade at the scene.\n","Video taken from an outside security camera showed a huge fireball\n","inside what appears to be the main entrance of the three-story stone\n","building, followed by a steady trail of smoke coming out of shattered\n","windows. Russia's security challenge . In July, Doku Umarov, the\n","leader of the Chechen group Caucasus Emirate, released a video\n","statement in which he vowed to unleash \"maximum force\" to disrupt the\n","games at Sochi. The U.S. State Department considers the Caucasus\n","Emirate a foreign terrorist group and has authorized a reward of up to\n","$5 million for information leading to the location of Umarov. The\n","State Department said Umarov organized a suicide bombing outside the\n","Chechen Interior Ministry in May 2009. His group also claimed\n","responsibility for the 2011 bombing of Domodedovo Airport in Moscow\n","that killed 36 people, the 2010 bombings of the Moscow subway that\n","killed 40 and the 2009 bombing of the high-speed Nevsky Express train\n","in which 28 people died. In October, a bomber blew up a passenger bus\n","in Volgograd, killing six people and wounding more than 30 others.\n","Russian media reported that a female Islamist suicide bomber from the\n","Russian region of Dagestan was responsible for that attack. \"Most of\n","the militants responsible for terrorist attacks in Russia over the\n","last decade -- including female suicide bombers who have taken part in\n","20 attacks claiming at least 780 lives since June 2000 -- have come\n","from Dagestan,\" RIA Novosti reported Monday. The two young men behind\n","the Boston Marathon bombings lived briefly in Dagestan before coming\n","to the United States, and one of them visited the area the year before\n","the attack. \"Radical Islamist groups tied to the war against the\n","Russian state now have much deeper roots, and are far more active, in\n","Dagestan than in Chechnya,\" Rajan Menon, senior fellow at the Atlantic\n","Council, wrote in a CNN.com column. What might be behind the attacks?\n","Putin has maintained that the Sochi games will be safe and security\n","will be tight. Visitors to Sochi and the surrounding area are\n","subjected to rigorous security checks, and vehicle license plates are\n","monitored. \"This will probably be one of the most difficult Olympics\n","to actually go as a spectator and watch the Games because of the\n","myriad layers of security,\" Republican Rep. Michael Grimm of New York\n","told CNN on Monday. Other parts of Russia . However, the Volgograd\n","explosions showed the challenge that Russian authorities face in\n","policing the rest of the country amid ongoing unrest in the North\n","Caucasus. That region includes Chechnya, where Russia fought two wars\n","against separatist movements, and Dagestan. With tight security around\n","Sochi itself, terrorists are believed to be focusing on other parts of\n","the North Caucasus and southern Russia. RIA Novosti reported a car\n","bomb killed three people on Friday in Pyatigorsk in southern Russia,\n","about 160 miles (270 kilometers) east of Sochi. \"Rarely do you\n","actually have a terrorist group come out and say, 'We're going to try\n","and disrupt these games,'\" CNN national security analyst Fran Townsend\n","said Monday. \"When al Qaeda-related affinity groups make these sort of\n","statements, you've got to take them at their word.\" The fact that the\n","bombers are targeting transportation is \"not lost on Olympic Committee\n","organizers and security officials,\" she added. Athletes are \"most\n","vulnerable\" when moving between the Olympic Village and the sites of\n","their events, she said. Townsend, who coordinated with Greek officials\n","before the Olympics in Athens in 2004, said security officials all\n","over the world will be asking Russia for detailed information about\n","these attacks, including whether there were any indications or\n","warnings. They'll also ask about what information Russian intelligence\n","has on the capabilities of terrorist groups to pull off further\n","attacks.<EOS><pad>U.S. legislator says spectators will face tight\n","Olympics security . Russia's foreign ministry vowed a continued\n","\"tough\" offensive against terrorism . Two terrorist bombings hit\n","Volgograd, killing more than 30 people . The attacks raised concerns\n","about security at the Olympics in February .<EOS>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T4sDS1WIVaYG"},"source":["<a name='1.3'></a>\n","\n","## 1.3 Batching with bucketing\n","\n","As in the previous assignment, we use bucketing to create batches of data."]},{"cell_type":"code","metadata":{"id":"oqj1NsbERWQX"},"source":["# Bucketing to create batched generators.\n","\n","# Buckets are defined in terms of boundaries and batch sizes.\n","# Batch_sizes[i] determines the batch size for items with length < boundaries[i]\n","# So below, we'll take a batch of 16 sentences of length < 128 , 8 of length < 256,\n","# 4 of length < 512. And so on. \n","boundaries =  [128, 256,  512, 1024]\n","batch_sizes = [16,    8,    4,    2, 1]\n","\n","# Create the streams.\n","train_batch_stream = trax.data.BucketByLength(\n","    boundaries, batch_sizes)(train_stream)\n","\n","eval_batch_stream = trax.data.BucketByLength(\n","    boundaries, batch_sizes)(eval_stream)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P6M5OA8QRWQb","executionInfo":{"elapsed":521646,"status":"ok","timestamp":1619797653237,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"8d7b1cfd-ad24-47b4-d1cf-f434ac42dd08"},"source":["# Every execution will result in generation of a different article\n","# Try running this cell multiple times to see how the length of the examples affects the batch size\n","input_batch, _, mask_batch = next(train_batch_stream)\n","\n","# Shape of the input_batch\n","input_batch.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 1024)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SjNOlljxTGuQ","executionInfo":{"elapsed":521638,"status":"ok","timestamp":1619797653238,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"75518c39-37bb-432b-a90d-f9008dd9a8bf"},"source":["# print corresponding integer values\n","print(input_batch[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 1683 12636  4968  4152 27068  7472     5    23 13293    15  1001    49\n","  9777    19   320   802  3710   320   213  6268   951     2  1786 22538\n","   527  1687 21442    10    32   446     3 16909   882 20447   415   132\n","   213  2202   385     6   236   599   809  5715 12831    20    78   389\n","   486     2  1248  4645  4677 12478  6183     7     5   384  9594   320\n","  4182   213  1687 11562    75  1153 25603     4   527  6268   951  3710\n","     3   200     2   170  1683 12636   955   320   213   448 12069   809\n","   213    60  1913     2    41   143  1151  2025   320  1153    64    44\n","    74   605   527   285   132 26536   155   213  2181   951     7     5\n","  5863  7823 10727  3633     3   129     7   165  2127    11 18381   713\n"," 16909  4968  4152 27068  7472     5   465    15  1001  1202     7    26\n","    18   320   802  3710   379 11765   320  5715 12831    20    11 16909\n","   511    31   138   123   320   213   385     6   236   599   102  3159\n","     6    55   214 11907   163   379  4439    78   220   104     7     5\n","  2891     2 16909    62    18   320  1153  1687  2910    10  1742    75\n","   122    41  1435  5125   166    31  1687  2069    10  1920    75  5970\n","    25    90   525   132  8405   527   213  1687  3545    75  1325   691\n","   213  2181   951     3  9884  4677 12478  6183     7     5   384  1558\n","   132   213  2202     2   487     2    41    62  1151 13463   320    28\n","  2387 13326 21267    79     3  1683 12636    18  1958   320  2306    31\n","  8626  2931   691  3438   208     6 20440   212   106   412  6381  5038\n","  3135   186  8676   213  7805   527  2822   251 20632    20   186 22355\n","     4  2621 18075    26    64    78  5391     3 14333    17    11  4450\n"," 25838  6404 27068  7472     5   465  1683 12636  1435   132    28   499\n","   845   586    74    72    91  1008   379 20003     4    11  1683 12636\n"," 20064  4006  8134  4075   213  1857   320  6775  5928   213  2365   132\n","   213   385     6   236   270  6098   379 27068  7472     5   793  9355\n","  1833  5602 26158     4  3611  3175     2    51    49     8  9777    19\n","   320   273    61    24    13     7    75   163 26293 13764    26   691\n","  2129    70   849    13   108    19  1755   103  6510     7   129     7\n","   183   793   213  1487     2   647    51   273    61   181    51   358\n","     7    26     2    51     7   165   265  1019   213   209   632  1782\n","   129   288  2754   724    51   483   809   213  1001   186    51    39\n","   952   213  3007   647    51     7   165   132   213  2202   181   213\n","  6268   951  1782   129  1435    28   196 21065    81     2   196 11282\n","    81   260   527   101    74    51    25    72    91  1008  2002  8647\n"," 15131    11  1683 12636     7     5  5915   320  2306    31  8626  9932\n","   569   236     6 11396   807   106   669   391   412  6381  5038  3135\n","   379  3000  2033    11  2822   251 20632    20     8   231    12   533\n","    78  5391   320 10665   186  2696   373  1751  1019  5179  3176  4299\n","   558     7     5   384  2104     1     0 18381   713 16909    18 22538\n","   527  1687 21442    10    32   446 16346 27439  6774  1628     9  1001\n","   229    43   284   320  1151  1205  1248 26536   155  5863  7823 10727\n","  1370 16346 27439  6774  1628   200  4968  4152 27068  7472     5   465\n","    41    49  6416   341  1436  3710   320   213  6268   951   824   357\n"," 16346 27439  6774  1628  1683 12636   245    78 20447   132   213   385\n","     6   236   599   809  5715 12831    20    78   389   486  2104     1\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GD-72TENV2Jk"},"source":["Things to notice:\n"," - First we see the corresponding values of the words.\n"," - The first 1, which represents the `<EOS>` tag of the article.\n"," - Followed by a 0, which represents a `<pad>` tag.\n"," - After the first 0 (`<pad>` tag) the corresponding values are of the words that are used for the summary of the article.\n"," - The second 1 represents the `<EOS>` tag for the summary.\n"," - All the trailing 0s represent `<pad>` tags which are appended to maintain consistent length (If you don't see them then it would mean it is already of max length)\n"," "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bu05ZwbWTE6P","executionInfo":{"elapsed":522094,"status":"ok","timestamp":1619797653703,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"32cbb54a-fed8-4c74-b8d3-bdfb8254a870"},"source":["# print the article and its summary\n","print('Article:\\n\\n', detokenize(input_batch[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Article:\n","\n"," QPR chairman Tony Fernandes has insisted his club can afford not to\n","win promotion to the Premier League, despite debts of £177.1 million.\n","Rangers face Derby County in the Championship play-off final at\n","Wembley on May 24, with Harry Redknapp's side hoping to secure the\n","£120m pay packet of Premier League promotion. But, should QPR return\n","to the top tier at the first attempt, they could be forced to pay out\n","more than half of that in fines under the Football League's Financial\n","Fair Play regulations. We're ready: Queens Park Rangers chairman Tony\n","Fernandes says his club doesn't have to win promotion . Off to\n","Wembley: Rangers won their way through to the play-off final after\n","extra-time against Wigan . Based on last year's accounts, Rangers\n","would have to pay £62.1m if they are promoted because their £65.4m\n","losses were so far in excess of the £8m allowed by the Football\n","League. Should Redknapp's side stay in the Championship, however, they\n","would be subjected to a transfer embargo. QPR have tried to reduce\n","their wage bill by selling high-earners such as Christopher Samba and\n","sending the likes of Loic Remy and Adel Taarabt out on loan. Improved:\n","Businessman Fernandes says QPR are in a better financial position than\n","two years ago . Winner: QPR striker Charlie Austin finds the net to\n","snatch the victory in the play-off second leg . Fernandes told\n","talkSPORT: 'Yes, we can (afford not to go up). I'm an accountant by\n","background - although I may not seem it! 'We've told the fans, whether\n","we go up or we don't, we're here for the long term. 'We know what\n","culture we want at the club and we will continue the journey whether\n","we're in the Championship or the Premier League. 'We are a much\n","smarter, much wiser group of people than we were two years ago.'\n","Relief: QPR's bid to reduce their wage bills included off-loading\n","players such  as Christopher Samba . Major break: Loic Remy (right)\n","went on loan to Newcastle and scored 14 goals for Alan Pardew's side\n",".<EOS><pad>QueensPark Rangers have debts of £177.1 million . The club\n","is also set to be hit with fines under Financial Fair Play rules . But\n","chairman Tony Fernandes says they can survive without winning\n","promotion to the Premier League this season . QPR take on Derby in the\n","play-off final at Wembley on May 24 .<EOS><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pa\n","d><pad><pad><pad><pad><pad><pad>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aNFVhgHoncGm"},"source":["You can see that the data has the following structure:\n","- <span style='color:blue'> [Article] </span> -> `<EOS>` -> `<pad>` -> <span style='color:blue'> [Article Summary] </span> -> `<EOS>` -> (possibly) multiple `<pad>`\n","\n","The loss is taken only on the summary using cross_entropy as loss function. "]},{"cell_type":"markdown","metadata":{"id":"Un8NHIRoj-1W"},"source":["<a name='2'></a>\n","# Part 2: Summarization with transformer\n","\n","Now that we have seen the data generator and have handled the preprocessing, it is time to build the model. \n","\n","You will be implementing the attention from scratch and then using it in your transformer model. Concretely, you will understand how attention works, how you use it to connect the encoder and the decoder.\n","\n","<img src=\"https://drive.google.com/file/d/1t8-qYgzwgG_jZOkt2U-DvKuqY1H5EAzB/view?usp=sharing\">\n","\n","<a name='2.1'></a>\n","## 2.1 Dot product attention \n","\n","Now you will implement dot product attention which takes in a query, key, value, and a mask. It returns the output. \n","\n","<img src =\"https://drive.google.com/file/d/1QYltnKMCs2pB5rMGuwYVdlHYg8jofH_N/view?usp=sharing\">\n","\n","\n","Here are some helper functions that will help you create tensors and display useful information:\n","   - `create_tensor`  creates a `jax numpy array` from a list of lists.\n","   - `display_tensor` prints out the shape and the actual tensor."]},{"cell_type":"code","metadata":{"id":"BFV4nJmYokkh"},"source":["def create_tensor(t):\n","    \"\"\"Create tensor from list of lists\"\"\"\n","    return jnp.array(t)\n","\n","\n","def display_tensor(t, name):\n","    \"\"\"Display shape and tensor\"\"\"\n","    print(f'{name} shape: {t.shape}\\n')\n","    print(f'{t}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GTq0A4lcokki"},"source":["Before implementing it yourself, you can play around with a toy example of `dot product attention` without the softmax  operation. Technically it would not be `dot product attention` without the softmax but this is done to avoid giving away too much of the answer and the idea is to display these tensors to give you a sense of how they look like.\n","\n","The formula for attention is this one:\n","\n","$$\n","\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n","$$\n","\n","$d_{k}$ stands for the dimension of queries and keys.\n","\n","The `query`, `key`, `value` and `mask` vectors are provided for this example.\n","\n","Notice that the masking is done using very negative values that will yield a similar effect to using $-\\infty $. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0x0HJXwRWQk","executionInfo":{"elapsed":522084,"status":"ok","timestamp":1619797653704,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"a2b14ed5-9a02-4f93-e53d-542814465489"},"source":["q = create_tensor([[1, 0, 0], [0, 1, 0]])\n","display_tensor(q, 'query')\n","k = create_tensor([[1, 2, 3], [4, 5, 6]])\n","display_tensor(k, 'key')\n","v = create_tensor([[0, 1, 0], [1, 0, 1]])\n","display_tensor(v, 'value')\n","m = create_tensor([[0, 0], [-1e9, 0]])\n","display_tensor(m, 'mask')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["query shape: (2, 3)\n","\n","[[1 0 0]\n"," [0 1 0]]\n","\n","key shape: (2, 3)\n","\n","[[1 2 3]\n"," [4 5 6]]\n","\n","value shape: (2, 3)\n","\n","[[0 1 0]\n"," [1 0 1]]\n","\n","mask shape: (2, 2)\n","\n","[[ 0.e+00  0.e+00]\n"," [-1.e+09  0.e+00]]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FlazZXCookki"},"source":["**Expected Output:**\n","```CPP\n","query shape: (2, 3)\n","\n","[[1 0 0]\n"," [0 1 0]]\n","\n","key shape: (2, 3)\n","\n","[[1 2 3]\n"," [4 5 6]]\n","\n","value shape: (2, 3)\n","\n","[[0 1 0]\n"," [1 0 1]]\n","\n","mask shape: (2, 2)\n","\n","[[ 0.e+00  0.e+00]\n"," [-1.e+09  0.e+00]]\n","\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kVR9u4faRWQo","executionInfo":{"elapsed":523112,"status":"ok","timestamp":1619797654741,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"c8ff70a9-6000-4d5a-999b-d82aa494f633"},"source":["q_dot_k = q @ k.T / jnp.sqrt(3)\n","display_tensor(q_dot_k, 'query dot key')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["query dot key shape: (2, 2)\n","\n","[[0.57735026 2.309401  ]\n"," [1.1547005  2.8867512 ]]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SQs2g-dkokkj"},"source":["**Expected Output:**\n","```CPP\n","query dot key shape: (2, 2)\n","\n","[[0.57735026 2.309401  ]\n"," [1.1547005  2.8867514 ]]\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T5fKh_0Cokkj","executionInfo":{"elapsed":523104,"status":"ok","timestamp":1619797654742,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"13b9a60a-0ba6-4aae-bd69-39fb34105105"},"source":["masked = q_dot_k + m\n","display_tensor(masked, 'masked query dot key')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["masked query dot key shape: (2, 2)\n","\n","[[ 5.7735026e-01  2.3094010e+00]\n"," [-1.0000000e+09  2.8867512e+00]]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OwKCu81Gokkk"},"source":["**Expected Output:**\n","```CPP\n","masked query dot key shape: (2, 2)\n","\n","[[ 5.7735026e-01  2.3094010e+00]\n"," [-1.0000000e+09  2.8867514e+00]]\n","```"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bua_7ZTQokkk","executionInfo":{"elapsed":525504,"status":"ok","timestamp":1619797657151,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"2ad8341c-71ca-459d-ae7a-21b9eb24e773"},"source":["display_tensor(masked @ v, 'masked query dot key dot value')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["masked query dot key dot value shape: (2, 3)\n","\n","[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n"," [ 2.8867512e+00 -1.0000000e+09  2.8867512e+00]]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JToCEKRIokkk"},"source":["**Expected Output:**\n","```CPP\n","masked query dot key dot value shape: (2, 3)\n","\n","[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n"," [ 2.8867514e+00 -1.0000000e+09  2.8867514e+00]]\n","```"]},{"cell_type":"markdown","metadata":{"id":"ihkar8NZokkl"},"source":["In order to use the previous dummy tensors in trax models, a batch dimension should be added to them so they mimic the shape of real-life examples. The mask is also replaced by a version of it that resembles the one that is used by trax:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DJIA5QNFokkl","executionInfo":{"elapsed":525494,"status":"ok","timestamp":1619797657152,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"80d5a94e-a1f5-417c-898d-4628dffb6863"},"source":["q_with_batch = q[None,:]\n","display_tensor(q_with_batch, 'query with batch dim')\n","k_with_batch = k[None,:]\n","display_tensor(k_with_batch, 'key with batch dim')\n","v_with_batch = v[None,:]\n","display_tensor(v_with_batch, 'value with batch dim')\n","m_bool = create_tensor([[True, True], [False, True]])\n","display_tensor(m_bool, 'boolean mask')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["query with batch dim shape: (1, 2, 3)\n","\n","[[[1 0 0]\n","  [0 1 0]]]\n","\n","key with batch dim shape: (1, 2, 3)\n","\n","[[[1 2 3]\n","  [4 5 6]]]\n","\n","value with batch dim shape: (1, 2, 3)\n","\n","[[[0 1 0]\n","  [1 0 1]]]\n","\n","boolean mask shape: (2, 2)\n","\n","[[ True  True]\n"," [False  True]]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0qjYQkMWokkl"},"source":["**Expected Output:**\n","```CPP\n","query with batch dim shape: (1, 2, 3)\n","\n","[[[1 0 0]\n","  [0 1 0]]]\n","\n","key with batch dim shape: (1, 2, 3)\n","\n","[[[1 2 3]\n","  [4 5 6]]]\n","\n","value with batch dim shape: (1, 2, 3)\n","\n","[[[0 1 0]\n","  [1 0 1]]]\n","\n","boolean mask shape: (2, 2)\n","\n","[[ True  True]\n"," [False  True]]\n","```"]},{"cell_type":"markdown","metadata":{"id":"oeoCg_xdokkm"},"source":["<a name='ex01'></a>\n","### Exercise 01\n","\n","**Instructions:** Implement the dot product attention. Concretely, implement the following equation\n","\n","\n","$$\n","\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n","$$\n","\n","$Q$ - query, \n","$K$ - key, \n","$V$ - values, \n","$M$ - mask, \n","${d_k}$ - depth/dimension of the queries and keys (used for scaling down)\n","\n","You can implement this formula either by `trax` numpy (trax.math.numpy) or regular `numpy` but it is recommended to use `jnp`.\n","\n","Something to take into consideration is that within trax, the masks are tensors of `True/False` values not 0's and $-\\infty$ as in the previous example. Within the graded function don't think of applying the mask by summing up matrices, instead use `jnp.where()` and treat the **mask as a tensor of boolean values with `False` for values that need to be masked and True for the ones that don't.**\n","\n","Also take into account that the real tensors are far more complex than the toy ones you just played with. Because of this avoid using shortened operations such as `@` for dot product or `.T` for transposing. Use `jnp.matmul()` and `jnp.swapaxes()` instead.\n","\n","This is the self-attention block for the transformer decoder. Good luck!  "]},{"cell_type":"code","metadata":{"id":"kSauPt0NUl_o"},"source":["def DotProductAttention(query, key, value, mask):\n","    \"\"\"Dot product self-attention.\n","    Args:\n","        query (jax.interpreters.xla.DeviceArray): array of query representations with shape (L_q by d)\n","        key (jax.interpreters.xla.DeviceArray): array of key representations with shape (L_k by d)\n","        value (jax.interpreters.xla.DeviceArray): array of value representations with shape (L_k by d) where L_v = L_k\n","        mask (jax.interpreters.xla.DeviceArray): attention-mask, gates attention with shape (L_q by L_k)\n","\n","    Returns:\n","        jax.interpreters.xla.DeviceArray: Self-attention array for q, k, v arrays. (L_q by L_k)\n","    \"\"\"\n","\n","    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"Embedding dimensions of q, k, v aren't all the same\"\n","\n","    # Save depth/dimension of the query embedding for scaling down the dot product\n","    depth = query.shape[-1] \n","\n","    # Calculate scaled query key dot product according to formula above\n","    dots = jnp.matmul(query, jnp.swapaxes(key, -1, -2)) / jnp.sqrt(depth)\n","    \n","    # Apply the mask\n","    if mask is not None: # The 'None' in this line does not need to be replaced\n","        dots = jnp.where(mask, dots, jnp.full_like(dots, -1e9))\n","    \n","    # Softmax formula implementation\n","    # Use trax.fastmath.logsumexp of dots to avoid underflow by division by large numbers\n","    # Hint: Last axis should be used and keepdims should be True\n","    # Note: softmax = e^(dots - logsumexp(dots)) = E^dots / sumexp(dots)\n","    logsumexp = trax.fastmath.logsumexp(dots, axis=-1, keepdims=True)\n","\n","    # Take exponential of dots minus logsumexp to get softmax\n","    # Use jnp.exp()\n","    dots = jnp.exp(dots - logsumexp)\n","\n","    # Multiply dots by value to get self-attention\n","    # Use jnp.matmul()\n","    attention = jnp.matmul(dots, value)\n","    \n","    return attention"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8o0K7VWKRWQw","executionInfo":{"elapsed":527222,"status":"ok","timestamp":1619797658891,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"ec81688f-6b33-42f3-f0ec-1b0f1fbc1893"},"source":["DotProductAttention(q_with_batch, k_with_batch, v_with_batch, m_bool)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DeviceArray([[[0.8496746 , 0.15032546, 0.8496746 ],\n","              [1.        , 0.        , 1.        ]]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"VyLMMqNCokkq"},"source":["**Expected Output:**\n","```CPP\n","DeviceArray([[[0.8496746 , 0.15032545, 0.8496746 ],\n","              [1.        , 0.        , 1.        ]]], dtype=float32)\n","```    "]},{"cell_type":"markdown","metadata":{"id":"2y2PSiLVRWQ2"},"source":["<a name='2.2'></a>\n","\n","## 2.2 Causal Attention\n","\n","Now you are going to implement causal attention: multi-headed attention with a mask to attend only to words that occurred before. \n","\n","<img src = \"https://drive.google.com/file/d/1-oYCnga-7QDymzHRtXicmrtH1eQbM7OA/view?usp=sharing\">\n","\n","In the image above, a word can see everything that is before it, but not what is after it. To implement causal attention, you will have to transform vectors and do many reshapes. You will need to implement the functions below.\n","\n","\n","<a name='ex02'></a>\n","### Exercise 02\n","\n","Implement the following functions that will be needed for Causal Attention:\n","\n","- <span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (batch_size, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size $\\times$ n_heads, seqlen, d_head).\n","- <span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention.\n","- <span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (batch_size, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. \n","\n","Next there are some toy tensors which may serve to give you an idea of the data shapes and opperations involved in Causal Attention. They are also useful to test out your functions! "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRH67YcrRWQ3","executionInfo":{"elapsed":527212,"status":"ok","timestamp":1619797658891,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"da304ebb-4fb4-473e-e72c-462b70b505f3"},"source":["tensor2d = create_tensor(q)\n","display_tensor(tensor2d, 'query matrix (2D tensor)')\n","\n","tensor4d2b = create_tensor([[q, q], [q, q]])\n","display_tensor(tensor4d2b, 'batch of two (multi-head) collections of query matrices (4D tensor)')\n","\n","tensor3dc = create_tensor([jnp.concatenate([q, q], axis = -1)])\n","display_tensor(tensor3dc, 'one batch of concatenated heads of query matrices (3d tensor)')\n","\n","tensor3dc3b = create_tensor([jnp.concatenate([q, q], axis = -1), jnp.concatenate([q, q], axis = -1), jnp.concatenate([q, q], axis = -1)])\n","display_tensor(tensor3dc3b, 'three batches of concatenated heads of query matrices (3d tensor)')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["query matrix (2D tensor) shape: (2, 3)\n","\n","[[1 0 0]\n"," [0 1 0]]\n","\n","batch of two (multi-head) collections of query matrices (4D tensor) shape: (2, 2, 2, 3)\n","\n","[[[[1 0 0]\n","   [0 1 0]]\n","\n","  [[1 0 0]\n","   [0 1 0]]]\n","\n","\n"," [[[1 0 0]\n","   [0 1 0]]\n","\n","  [[1 0 0]\n","   [0 1 0]]]]\n","\n","one batch of concatenated heads of query matrices (3d tensor) shape: (1, 2, 6)\n","\n","[[[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]]\n","\n","three batches of concatenated heads of query matrices (3d tensor) shape: (3, 2, 6)\n","\n","[[[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]\n","\n"," [[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]\n","\n"," [[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vxDCI0JAokkr"},"source":["It is important to know that the following 3 functions would normally be defined within the `CausalAttention` function further below. \n","\n","However this makes these functions harder to test. Because of this, these functions are shown individually using a `closure` (when necessary) that simulates them being inside of the `CausalAttention` function. This is done because they rely on some variables that can be accessed from within `CausalAttention`.\n","\n","### Support Functions\n","\n","<span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (batch_size, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size $\\times$ n_heads, seqlen, d_head).\n"]},{"cell_type":"code","metadata":{"id":"TDvTNK6eokkr"},"source":["def compute_attention_heads_closure(n_heads, d_head):\n","    \"\"\" Function that simulates environment inside CausalAttention function.\n","    Args:\n","        d_head (int):  dimensionality of heads.\n","        n_heads (int): number of attention heads.\n","    Returns:\n","        function: compute_attention_heads function\n","    \"\"\"\n","\n","    def compute_attention_heads(x):\n","        \"\"\" Compute the attention heads.\n","        Args:\n","            x (jax.interpreters.xla.DeviceArray): tensor with shape (batch_size, seqlen, n_heads X d_head).\n","        Returns:\n","            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size X n_heads, seqlen, d_head).\n","        \"\"\"\n","        # Size of the x's batch dimension\n","        batch_size = x.shape[0]\n","        # Length of the sequence\n","        # Should be size of x's first dimension without counting the batch dim\n","        seqlen = x.shape[1]\n","        # Reshape x using jnp.reshape()\n","        # batch_size, seqlen, n_heads*d_head -> batch_size, seqlen, n_heads, d_head\n","        x = jnp.reshape(x, (batch_size, seqlen, n_heads, d_head))\n","        # Transpose x using jnp.transpose()\n","        # batch_size, seqlen, n_heads, d_head -> batch_size, n_heads, seqlen, d_head\n","        # Note that the values within the tuple are the indexes of the dimensions of x and you must rearrange them\n","        x = jnp.transpose(x, (0, 2, 1, 3))\n","        # Reshape x using jnp.reshape()\n","        # batch_size, n_heads, seqlen, d_head -> batch_size*n_heads, seqlen, d_head\n","        x = jnp.reshape(x, (-1, seqlen, d_head))\n","\n","        return x\n","    \n","    return compute_attention_heads"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0NsqU_Sokkr","executionInfo":{"elapsed":527867,"status":"ok","timestamp":1619797659557,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"30256a19-24e7-4ed3-a7fb-c389bd25e936"},"source":["display_tensor(tensor3dc3b, \"input tensor\")\n","result_cah = compute_attention_heads_closure(2,3)(tensor3dc3b)\n","display_tensor(result_cah, \"output tensor\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["input tensor shape: (3, 2, 6)\n","\n","[[[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]\n","\n"," [[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]\n","\n"," [[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]]\n","\n","output tensor shape: (6, 2, 3)\n","\n","[[[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5FDE4AEIokks"},"source":["**Expected Output:**\n","```CPP\n","input tensor shape: (3, 2, 6)\n","\n","[[[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]\n","\n"," [[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]\n","\n"," [[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]]\n","\n","output tensor shape: (6, 2, 3)\n","\n","[[[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]]\n","```"]},{"cell_type":"markdown","metadata":{"id":"MogWaMxKokks"},"source":["<span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention."]},{"cell_type":"code","metadata":{"id":"JMO66vEkokkt"},"source":["def dot_product_self_attention(q, k, v):\n","    \"\"\" Masked dot product self attention.\n","    Args:\n","        q (jax.interpreters.xla.DeviceArray): queries.\n","        k (jax.interpreters.xla.DeviceArray): keys.\n","        v (jax.interpreters.xla.DeviceArray): values.\n","    Returns:\n","        jax.interpreters.xla.DeviceArray: masked dot product self attention tensor.\n","    \"\"\"\n","    # Hint: mask size should be equal to L_q. Remember that q has shape (batch_size, L_q, d)\n","    # NOTE: there is a revision underway with the autograder to tolerate better indexing. \n","    # Until then, please index q.shape using negative values (this is equivalent to counting from right to left)\n","    mask_size = q.shape[-2]\n","\n","    # Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)\n","    # Notice that 1's and 0's get casted to True/False by setting dtype to jnp.bool_\n","    # Use jnp.tril() - Lower triangle of an array and jnp.ones()\n","    mask = jnp.tril(jnp.ones((1, mask_size, mask_size), dtype=jnp.bool_), k=0)\n","    \n","    return DotProductAttention(q, k, v, mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_jLnM1Cokkt","executionInfo":{"elapsed":528365,"status":"ok","timestamp":1619797660067,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"22278fa7-77e4-4345-ed36-394561f7c900"},"source":["dot_product_self_attention(q_with_batch, k_with_batch, v_with_batch)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DeviceArray([[[0.        , 1.        , 0.        ],\n","              [0.8496746 , 0.15032548, 0.8496746 ]]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"2hWhkmJsokku"},"source":["**Expected Output:**\n","```CPP\n","DeviceArray([[[0.        , 1.        , 0.        ],\n","              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)\n","```"]},{"cell_type":"markdown","metadata":{"id":"U2ZpddC7okku"},"source":["<span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (batch_size, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. "]},{"cell_type":"code","metadata":{"id":"06P3-vYWokku"},"source":["def compute_attention_output_closure(n_heads, d_head):\n","    \"\"\" Function that simulates environment inside CausalAttention function.\n","    Args:\n","        d_head (int):  dimensionality of heads.\n","        n_heads (int): number of attention heads.\n","    Returns:\n","        function: compute_attention_output function\n","    \"\"\"\n","    \n","    def compute_attention_output(x):\n","        \"\"\" Compute the attention output.\n","        Args:\n","            x (jax.interpreters.xla.DeviceArray): tensor with shape (batch_size X n_heads, seqlen, d_head).\n","        Returns:\n","            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size, seqlen, n_heads X d_head).\n","        \"\"\"\n","        # Length of the sequence\n","        # Should be size of x's first dimension without counting the batch dim\n","        seqlen = x.shape[1]\n","        # Reshape x using jnp.reshape() to shape (batch_size, n_heads, seqlen, d_head)\n","        x = jnp.reshape(x, ( -1, n_heads, seqlen, d_head))\n","        # Transpose x using jnp.transpose() to shape (batch_size, seqlen, n_heads, d_head)\n","        x = jnp.transpose(x, ( 0, 2, 1 , 3))\n","        \n","        # Reshape to allow to concatenate the heads\n","        return jnp.reshape(x, (-1, seqlen, n_heads * d_head))\n","    \n","    return compute_attention_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"blRVvzimokku","executionInfo":{"elapsed":528354,"status":"ok","timestamp":1619797660068,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"fb43e5ed-595f-4b49-8e55-74a2fc481e17"},"source":["display_tensor(result_cah, \"input tensor\")\n","result_cao = compute_attention_output_closure(2,3)(result_cah)\n","display_tensor(result_cao, \"output tensor\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["input tensor shape: (6, 2, 3)\n","\n","[[[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]]\n","\n","output tensor shape: (3, 2, 6)\n","\n","[[[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]\n","\n"," [[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]\n","\n"," [[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4DU3omh7okkv"},"source":["**Expected Output:**\n","```CPP\n","input tensor shape: (6, 2, 3)\n","\n","[[[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]\n","\n"," [[1 0 0]\n","  [0 1 0]]]\n","\n","output tensor shape: (3, 2, 6)\n","\n","[[[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]\n","\n"," [[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]\n","\n"," [[1 0 0 1 0 0]\n","  [0 1 0 0 1 0]]]\n","```"]},{"cell_type":"markdown","metadata":{"id":"sCGXIaPOokkv"},"source":["### Causal Attention Function\n","\n","Now it is time for you to put everything together within the `CausalAttention` or Masked multi-head attention function:"]},{"cell_type":"markdown","metadata":{"id":"s2qq3sk-okkv"},"source":["<img src = \"https://drive.google.com/file/d/1lFS2zxRxMAN6RCUudiMsbrQLFpUpU1kG/view?usp=sharing\"> \n","\n","**Instructions:** Implement the causal attention.\n","Your model returns the causal attention through a $tl.Serial$ with the following:\n","\n","- <span style='color:blue'> [tl.Branch](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Branch) </span>: consisting of 3 [tl.Dense(d_feature), ComputeAttentionHeads] to account for the queries, keys, and values.\n","- <span style='color:blue'> [tl.Fn](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn)</span>: Takes in dot_product_self_attention function and uses it to compute the dot product using $Q$, $K$, $V$.\n","- <span style='color:blue'> [tl.Fn](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn)</span>: Takes in restack_attention_heads to allow for parallel computing.\n","- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense)</span>: Final Dense layer, with dimension `d_feature`.\n","\n","Remember that in order for trax to properly handle the functions you just defined, they need to be added as layers using the [`tl.Fn()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn) function. "]},{"cell_type":"code","metadata":{"id":"B9Adn6DtRWRG"},"source":["def CausalAttention(d_feature, \n","                    n_heads, \n","                    compute_attention_heads_closure=compute_attention_heads_closure,\n","                    dot_product_self_attention=dot_product_self_attention,\n","                    compute_attention_output_closure=compute_attention_output_closure,\n","                    mode='train'):\n","    \"\"\"Transformer-style multi-headed causal attention.\n","\n","    Args:\n","        d_feature (int):  dimensionality of feature embedding.\n","        n_heads (int): number of attention heads.\n","        compute_attention_heads_closure (function): Closure around compute_attention heads.\n","        dot_product_self_attention (function): dot_product_self_attention function. \n","        compute_attention_output_closure (function): Closure around compute_attention_output. \n","        mode (str): 'train' or 'eval'.\n","\n","    Returns:\n","        trax.layers.combinators.Serial: Multi-headed self-attention model.\n","    \"\"\"\n","    \n","    assert d_feature % n_heads == 0\n","    d_head = d_feature // n_heads\n","    \n","    # HINT: The second argument to tl.Fn() is an uncalled function (without the parentheses)\n","    # Since you are dealing with closures you might need to call the outer \n","    # function with the correct parameters to get the actual uncalled function.\n","    ComputeAttentionHeads = tl.Fn('AttnHeads', compute_attention_heads_closure(n_heads, d_head), n_out=1)\n","        \n","\n","    return tl.Serial(\n","        tl.Branch( # creates three towers for one input, takes activations and creates queries keys and values\n","            [tl.Dense(d_feature), ComputeAttentionHeads], # queries\n","            [tl.Dense(d_feature), ComputeAttentionHeads], # keys\n","            [tl.Dense(d_feature), ComputeAttentionHeads], # values\n","        ),\n","        \n","        tl.Fn('DotProductAttn', dot_product_self_attention, n_out=1), # takes QKV\n","        # HINT: The second argument to tl.Fn() is an uncalled function\n","        # Since you are dealing with closures you might need to call the outer \n","        # function with the correct parameters to get the actual uncalled function.\n","        tl.Fn('AttnOutput', compute_attention_output_closure(n_heads, d_head), n_out=1), # to allow for parallel\n","        tl.Dense(d_feature) # Final dense layer\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3kuc7eT2okkw","executionInfo":{"elapsed":528345,"status":"ok","timestamp":1619797660070,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"4389813b-b4d7-4232-efb6-59e4cb8b38cf"},"source":["# Take a look at the causal attention model\n","print(CausalAttention(d_feature=512, n_heads=8))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Serial[\n","  Branch_out3[\n","    [Dense_512, AttnHeads]\n","    [Dense_512, AttnHeads]\n","    [Dense_512, AttnHeads]\n","  ]\n","  DotProductAttn_in3\n","  AttnOutput\n","  Dense_512\n","]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SR5Phb8Cokkw"},"source":["**Expected Output:**\n","```CPP\n","Serial[\n","  Branch_out3[\n","    [Dense_512, AttnHeads]\n","    [Dense_512, AttnHeads]\n","    [Dense_512, AttnHeads]\n","  ]\n","  DotProductAttn_in3\n","  AttnOutput\n","  Dense_512\n","]\n","```"]},{"cell_type":"markdown","metadata":{"id":"W6zwtPjqRWRJ"},"source":["<a name='2.3'></a>\n","\n","## 2.3 Transformer decoder block\n","\n","Now that you have implemented the causal part of the transformer, you will implement the transformer decoder block. Concretely you will be implementing this image now.\n","\n","<img src = \"https://drive.google.com/file/d/1NeuEnDro6S60pm7usROAYEn-mRQNaujQ/view?usp=sharing\" style = \"height:300px\"> \n","\n","To implement this function, you will have to call the `CausalAttention` or Masked multi-head attention function you implemented above. You will have to add a feedforward which consists of: \n","\n","- <span style='color:blue'> [tl.LayerNorm](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) </span>: used to layer normalize\n","- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: the dense layer\n","- <span style='color:blue'> [ff_activation](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.activation_fns.Relu) </span>: feed forward activation (we use ReLu) here.\n","- <span style='color:blue'> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout) </span>: dropout layer\n","- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: dense layer\n","- <span style='color:blue'> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout) </span>: dropout layer\n","\n","Finally once you implement the feedforward, you can go ahead and implement the entire block using: \n","\n","- <span style='color:blue'> [tl.Residual](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) </span>: takes in the tl.LayerNorm(), causal attention block, tl.dropout. \n","\n","- <span style='color:blue'> [tl.Residual](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) </span>: takes in the feedforward block you will implement. \n","\n","<a name='ex03'></a>\n","### Exercise 03\n","**Instructions:** Implement the transformer decoder block. Good luck!"]},{"cell_type":"code","metadata":{"id":"gKOxnRbp1K5U"},"source":["def DecoderBlock(d_model, d_ff, n_heads,\n","                 dropout, mode, ff_activation):\n","    \"\"\"Returns a list of layers that implements a Transformer decoder block.\n","\n","    The input is an activation tensor.\n","\n","    Args:\n","        d_model (int):  depth of embedding.\n","        d_ff (int): depth of feed-forward layer.\n","        n_heads (int): number of attention heads.\n","        dropout (float): dropout rate (how much to drop out).\n","        mode (str): 'train' or 'eval'.\n","        ff_activation (function): the non-linearity in feed-forward layer.\n","\n","    Returns:\n","        list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.\n","    \"\"\"\n","    # Create masked multi-head attention block using CausalAttention function\n","    causal_attention = CausalAttention( \n","                        d_model,\n","                        n_heads=n_heads,\n","                        mode=mode\n","                        )\n","\n","    # Create feed-forward block (list) with two dense layers with dropout and input normalized\n","    feed_forward = [ \n","        # Normalize layer inputs\n","        tl.LayerNorm(),\n","        # Add first feed forward (dense) layer (don't forget to set the correct value for n_units)\n","        tl.Dense(d_ff),\n","        # Add activation function passed in as a parameter (you need to call it!)\n","        ff_activation(), # Generally ReLU\n","        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n","        tl.Dropout(rate=dropout, mode=mode),\n","        # Add second feed forward layer (don't forget to set the correct value for n_units)\n","        tl.Dense(d_model),\n","        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n","        tl.Dropout(rate=dropout,mode=mode)\n","    ]\n","\n","    # Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks\n","    return [\n","      tl.Residual(\n","          # Normalize layer input\n","          tl.LayerNorm(),\n","          # Add causal attention block previously defined (without parentheses)\n","          causal_attention,\n","          # Add dropout with rate and mode specified\n","          tl.Dropout(rate=dropout, mode=mode)\n","        ),\n","      tl.Residual(\n","          # Add feed forward block (without parentheses)\n","          feed_forward\n","        ),\n","      ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaX5g0_Rokkx","executionInfo":{"elapsed":528334,"status":"ok","timestamp":1619797660071,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"c378b248-75b4-49c5-baa4-11ee2301c347"},"source":["# Take a look at the decoder block\n","print(DecoderBlock(d_model=512, d_ff=2048, n_heads=8, dropout=0.1, mode='train', ff_activation=tl.Relu))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Serial[\n","  Branch_out2[\n","    None\n","    Serial[\n","      LayerNorm\n","      Serial[\n","        Branch_out3[\n","          [Dense_512, AttnHeads]\n","          [Dense_512, AttnHeads]\n","          [Dense_512, AttnHeads]\n","        ]\n","        DotProductAttn_in3\n","        AttnOutput\n","        Dense_512\n","      ]\n","      Dropout\n","    ]\n","  ]\n","  Add_in2\n","], Serial[\n","  Branch_out2[\n","    None\n","    Serial[\n","      LayerNorm\n","      Dense_2048\n","      Serial[\n","        Relu\n","      ]\n","      Dropout\n","      Dense_512\n","      Dropout\n","    ]\n","  ]\n","  Add_in2\n","]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JIAGmDqEokkx"},"source":["**Expected Output:**\n","```CPP\n","[Serial[\n","  Branch_out2[\n","    None\n","    Serial[\n","      LayerNorm\n","      Serial[\n","        Branch_out3[\n","          [Dense_512, AttnHeads]\n","          [Dense_512, AttnHeads]\n","          [Dense_512, AttnHeads]\n","        ]\n","        DotProductAttn_in3\n","        AttnOutput\n","        Dense_512\n","      ]\n","      Dropout\n","    ]\n","  ]\n","  Add_in2\n","], Serial[\n","  Branch_out2[\n","    None\n","    Serial[\n","      LayerNorm\n","      Dense_2048\n","      Relu\n","      Dropout\n","      Dense_512\n","      Dropout\n","    ]\n","  ]\n","  Add_in2\n","]]\n","```"]},{"cell_type":"markdown","metadata":{"id":"SoFv-nfLRWRN"},"source":["<a name='2.4'></a>\n","## 2.4 Transformer Language Model\n","\n","You will now bring it all together. In this part you will use all the subcomponents you previously built to make the final model. Concretely, here is the image you will be implementing. \n","<img src = \"https://drive.google.com/file/d/1vXvKzjCxH2eWBsC0_kPfBhOS_DYHH-Jm/view?usp=sharing\" style = \"height:400px\">\n","\n","    \n","<a name='ex04'></a>\n","### Exercise 04\n","**Instructions:** Previously you coded the decoder block. Now you will code the transformer language model. Here is what you will need. \n","\n","- <span style=\"color:blue\"> positional_enconder </span>- a list containing the following layers:\n","    - <span style=\"color:blue\"> [tl.Embedding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding)\n","    - <span style=\"color:blue\"> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout)\n","    - <span style=\"color:blue\"> [tl.PositionalEncoding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.PositionalEncoding)\n","\n","- A list of `n_layers` <span style=\"color:blue\"> decoder blocks</span>.\n","- <span style=\"color:blue\"> [tl.Serial](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial): </span> takes in the following layers or lists of layers:\n","    - <span style=\"color:blue\"> [tl.ShiftRight](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.ShiftRight): </span>: shift the tensor to the right by padding on axis 1.\n","    - <span style=\"color:blue\"> positional_encoder </span>: encodes the text positions.\n","    - <span style=\"color:blue\"> decoder_blocks </span>: the ones you created.\n","    - <span style=\"color:blue\"> [tl.LayerNorm](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) </span>: a layer norm.\n","    - <span style=\"color:blue\"> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: takes in the vocab_size.\n","    - <span style=\"color:blue\"> [tl.LogSoftmax](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax) </span>: to predict.\n","    \n","Go go go!! You can do it :)\n","\n"]},{"cell_type":"code","metadata":{"id":"0yi4LJO1RWRS"},"source":["def TransformerLM(vocab_size=33300,\n","                  d_model=512,\n","                  d_ff=2048,\n","                  n_layers=6,\n","                  n_heads=8,\n","                  dropout=0.1,\n","                  max_len=4096,\n","                  mode='train',\n","                  ff_activation=tl.Relu):\n","    \"\"\"Returns a Transformer language model.\n","\n","    The input to the model is a tensor of tokens. (This model uses only the\n","    decoder part of the overall Transformer.)\n","\n","    Args:\n","        vocab_size (int): vocab size.\n","        d_model (int):  depth of embedding.\n","        d_ff (int): depth of feed-forward layer.\n","        n_layers (int): number of decoder layers.\n","        n_heads (int): number of attention heads.\n","        dropout (float): dropout rate (how much to drop out).\n","        max_len (int): maximum symbol length for positional encoding.\n","        mode (str): 'train', 'eval' or 'predict', predict mode is for fast inference.\n","        ff_activation (function): the non-linearity in feed-forward layer.\n","\n","    Returns:\n","        trax.layers.combinators.Serial: A Transformer language model as a layer that maps from a tensor of tokens\n","        to activations over a vocab set.\n","    \"\"\"\n","    # Embedding inputs and positional encoder\n","    positional_encoder = [ \n","        # Add embedding layer of dimension (vocab_size, d_model)\n","        tl.Embedding(vocab_size, d_model),\n","        # Use dropout with rate and mode specified\n","        tl.Dropout(rate=dropout, mode=mode),\n","        # Add positional encoding layer with maximum input length and mode specified\n","        tl.PositionalEncoding(max_len=max_len, mode=mode)]\n","\n","    # Create stack (list) of decoder blocks with n_layers with necessary parameters\n","    decoder_blocks = [ \n","        DecoderBlock(d_model, d_ff, n_heads,\n","                    dropout, mode, ff_activation) for _ in range(n_layers)]\n","\n","    # Create the complete model as written in the figure\n","    return tl.Serial(\n","        # Use teacher forcing (feed output of previous step to current step)\n","        tl.ShiftRight(mode=mode), # Specify the mode!\n","        # Add positional encoder\n","        positional_encoder,\n","        # Add decoder blocks\n","        decoder_blocks,\n","        # Normalize layer\n","        tl.LayerNorm(),\n","\n","        # Add dense layer of vocab_size (since need to select a word to translate to)\n","        # (a.k.a., logits layer. Note: activation already set by ff_activation)\n","        tl.Dense(vocab_size),\n","        # Get probabilities with Logsoftmax\n","        tl.LogSoftmax()\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GaKiLpMNokky","executionInfo":{"elapsed":528320,"status":"ok","timestamp":1619797660072,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"},"user_tz":-330},"outputId":"f819c605-a247-4f73-fc52-9462c13aa696"},"source":["# Take a look at the Transformer\n","print(TransformerLM(n_layers=1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Serial[\n","  Serial[\n","    ShiftRight(1)\n","  ]\n","  Embedding_33300_512\n","  Dropout\n","  PositionalEncoding\n","  Serial[\n","    Branch_out2[\n","      None\n","      Serial[\n","        LayerNorm\n","        Serial[\n","          Branch_out3[\n","            [Dense_512, AttnHeads]\n","            [Dense_512, AttnHeads]\n","            [Dense_512, AttnHeads]\n","          ]\n","          DotProductAttn_in3\n","          AttnOutput\n","          Dense_512\n","        ]\n","        Dropout\n","      ]\n","    ]\n","    Add_in2\n","  ]\n","  Serial[\n","    Branch_out2[\n","      None\n","      Serial[\n","        LayerNorm\n","        Dense_2048\n","        Serial[\n","          Relu\n","        ]\n","        Dropout\n","        Dense_512\n","        Dropout\n","      ]\n","    ]\n","    Add_in2\n","  ]\n","  LayerNorm\n","  Dense_33300\n","  LogSoftmax\n","]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rc_4gjT9okky"},"source":["**Expected Output:**\n","```CPP\n","Serial[\n","  ShiftRight(1)\n","  Embedding_33300_512\n","  Dropout\n","  PositionalEncoding\n","  Serial[\n","    Branch_out2[\n","      None\n","      Serial[\n","        LayerNorm\n","        Serial[\n","          Branch_out3[\n","            [Dense_512, AttnHeads]\n","            [Dense_512, AttnHeads]\n","            [Dense_512, AttnHeads]\n","          ]\n","          DotProductAttn_in3\n","          AttnOutput\n","          Dense_512\n","        ]\n","        Dropout\n","      ]\n","    ]\n","    Add_in2\n","  ]\n","  Serial[\n","    Branch_out2[\n","      None\n","      Serial[\n","        LayerNorm\n","        Dense_2048\n","        Relu\n","        Dropout\n","        Dense_512\n","        Dropout\n","      ]\n","    ]\n","    Add_in2\n","  ]\n","  LayerNorm\n","  Dense_33300\n","  LogSoftmax\n","]\n","```"]},{"cell_type":"markdown","metadata":{"id":"dRRKnoAdvmJ7"},"source":["<a name='3'></a>\n","# Part 3: Training\n","\n","Now you are going to train your model. As usual, you have to define the cost function, the optimizer, and decide whether you will be training it on a `gpu` or `cpu`. In this case, you will train your model on a cpu for a few steps and we will load in a pre-trained model that you can use to predict with your own words."]},{"cell_type":"markdown","metadata":{"id":"l1lkVebQRWRV"},"source":["<a name='3.1'></a>\n","### 3.1 Training the model\n","\n","You will now write a function that takes in your model and trains it. To train your model you have to decide how many times you want to iterate over the entire data set. Each iteration is defined as an `epoch`. For each epoch, you have to go over all the data, using your training iterator.\n","\n","<a name='ex05'></a>\n","### Exercise 05\n","**Instructions:** Implement the `train_model` program below to train the neural network above. Here is a list of things you should do:\n","\n","- Create the train task by calling [`trax.supervised.training.TrainTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask) and pass in the following: \n","    - <span style='color:blue'> labeled_data </span> = train_gen\n","    - <span style='color:blue'> loss_fn </span> = [tl.CrossEntropyLoss()](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss)\n","    - <span style='color:blue'> optimizer </span> = [trax.optimizers.Adam(0.01)](https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam)\n","    - <span style='color:blue'> lr_schedule </span> = [lr_schedule](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.lr_schedules.warmup_and_rsqrt_decay)\n","\n","\n","- Create the eval task by calling [`trax.supervised.training.EvalTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask) and pass in the following: \n","    - <span style='color:blue'> labeled_data </span> = eval_gen\n","    - <span style='color:blue'> metrics </span> = tl.CrossEntropyLoss() and [tl.Accuracy()](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.Accuracy)\n","    \n","    \n","- Create the training loop by calling [`trax.supervised.Training.Loop`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop) and pass in the following: \n","    - <span style='color:blue'> TransformerLM </span> \n","    - <span style='color:blue'> train_task </span> \n","    - <span style='color:blue'> eval_task </span> = [eval_task]\n","    - <span style='color:blue'> output_dir</span> = output_dir\n","    \n","You will be using a cross entropy loss, with Adam optimizer. Please read the [Trax](https://trax-ml.readthedocs.io/en/latest/index.html) documentation to get a full understanding. \n","\n","The training loop that this function returns can be runned using the `run()` method by passing in the desired number of steps."]},{"cell_type":"code","metadata":{"id":"gM2gpu4xvjtX"},"source":["from trax.supervised import training\n","\n","def training_loop(TransformerLM, train_gen, eval_gen, output_dir = \"~/model\"):\n","    '''\n","    Input:\n","        TransformerLM (trax.layers.combinators.Serial): The model you are building.\n","        train_gen (generator): Training stream of data.\n","        eval_gen (generator): Evaluation stream of data.\n","        output_dir (str): folder to save your file.\n","        \n","    Returns:\n","        trax.supervised.training.Loop: Training loop.\n","    '''\n","    output_dir = os.path.expanduser(output_dir)  # trainer is an object\n","    lr_schedule = trax.lr.warmup_and_rsqrt_decay(n_warmup_steps=1000, max_value=0.01)\n","\n","    train_task = training.TrainTask( \n","      labeled_data=train_gen, # The training generator\n","      loss_layer=tl.CrossEntropyLoss(), # Loss function \n","      optimizer=trax.optimizers.Adam(0.01), # Optimizer (Don't forget to set LR to 0.01)\n","      lr_schedule=lr_schedule,\n","      n_steps_per_checkpoint=10\n","    )\n","\n","    eval_task = training.EvalTask( \n","      labeled_data=eval_gen, # The evaluation generator\n","      metrics=[tl.CrossEntropyLoss(), tl.Accuracy()] # CrossEntropyLoss and Accuracy\n","    )\n","\n","    loop = training.Loop(TransformerLM(d_model=4,\n","                                       d_ff=16,\n","                                       n_layers=1,\n","                                       n_heads=2,\n","                                       mode='train'),\n","                         train_task,\n","                         eval_tasks=[eval_task],\n","                         output_dir=output_dir)\n","    \n","    return loop"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a4JU7X-Qokkz"},"source":["Notice that the model will be trained for only 10 steps. \n","\n","Even with this constraint the model with the original default arguments took a very long time to finish. Because of this some parameters are changed when defining the model that is fed into the training loop in the function above."]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"BFRBTwSqRWRZ","outputId":"de5221c5-2a4e-4a6f-ec35-dea2ea6f9034"},"source":["# Should take around 1.5 minutes\n","!rm -f ~/model/model.pkl.gz\n","loop = training_loop(TransformerLM, train_batch_stream, eval_batch_stream)\n","loop.run(10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Step      1: Total number of trainable weights: 316336\n","Step      1: Ran 1 train steps in 3.81 secs\n","Step      1: train CrossEntropyLoss |  10.41532040\n","Step      1: eval  CrossEntropyLoss |  10.41379738\n","Step      1: eval          Accuracy |  0.00000000\n","\n","Step     10: Ran 9 train steps in 18.66 secs\n","Step     10: train CrossEntropyLoss |  10.41289043\n","Step     10: eval  CrossEntropyLoss |  10.41215229\n","Step     10: eval          Accuracy |  0.00000000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XKrEBjmskeWa"},"source":[" <a name='4'></a>\n"," # Part 4:  Evaluation  \n","\n","<a name='4.1'></a>\n","### 4.1 Loading in a trained model\n","\n","In this part you will evaluate by loading in an almost exact version of the model you coded, but we trained it for you to save you time, and can be found  at  https://drive.google.com/drive/folders/1Bxuu7HFPSp54R1f-TldvkfZ1UdamWJu3?usp=sharing\n","\n","Please download the pretrained model from the link and upload it to your colab environment.\n","\n","As you may have already noticed the model that you trained and the pretrained model share the same overall architecture but they have different values for some of the parameters:\n","\n","    \n","   `Original (pretrained) model: `                                 \n","                                       \n","    TransformerLM(vocab_size=33300, d_model=512, d_ff=2048, n_layers=6, n_heads=8, \n","                   dropout=0.1, max_len=4096, ff_activation=tl.Relu)\n","                   \n","   `Your model:`\n","   \n","    TransformerLM(d_model=4, d_ff=16, n_layers=1, n_heads=2)\n","   \n","   **Only the parameters shown for your model were changed. The others stayed the same.**"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"bRHow22F3jHp"},"source":["# !cp '/content/drive/MyDrive/data/m17/model.pkl.gz' '/content/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zWoSzR5tkoAx"},"source":["# Get the model architecture\n","model = TransformerLM(mode='eval')\n","\n","# Load the pre-trained weights\n","model.init_from_file('/content/drive/MyDrive/data/m17/model.pkl.gz', weights_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ilM9C8P3RWRf"},"source":["<a name='5'></a>\n","# Part 5: Testing with your own input\n","\n","You will now test your input. You are going to implement greedy decoding. This consists of two functions. The first one allows you to identify the next symbol. It gets the argmax of the output of your model and then returns that index. \n","\n","<a name='ex06'></a>\n","### Exercise 06\n","**Instructions:** Implement the next symbol function that takes in the cur_output_tokens and the trained model to return the index of the next word. "]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"rD_bXRCpRWRg"},"source":["def next_symbol(cur_output_tokens, model):\n","    \"\"\"Returns the next symbol for a given sentence.\n","\n","    Args:\n","        cur_output_tokens (list): tokenized sentence with EOS and PAD tokens at the end.\n","        model (trax.layers.combinators.Serial): The transformer model.\n","\n","    Returns:\n","        int: tokenized symbol.\n","    \"\"\"\n","    # current output tokens length\n","    token_length = len(cur_output_tokens)\n","    # calculate the minimum power of 2 big enough to store token_length\n","    # HINT: use np.ceil() and np.log2()\n","    # add 1 to token_length so np.log2() doesn't receive 0 when token_length is 0\n","    padded_length = 2**int(np.ceil(np.log2(token_length + 1)))\n","\n","    # Fill cur_output_tokens with 0's until it reaches padded_length\n","    padded = cur_output_tokens + [0] * (padded_length - token_length)\n","    padded_with_batch = np.array(padded)[None, :] # Don't replace this 'None'! This is a way of setting the batch dim\n","\n","    # model expects a tuple containing two padded tensors (with batch)\n","    output, _ = model((padded_with_batch, padded_with_batch))  \n","    # HINT: output has shape (1, padded_length, vocab_size)\n","    # To get log_probs you need to index output with 0 in the first dim\n","    # token_length in the second dim and all of the entries for the last dim.\n","    log_probs = output[0, token_length, :]\n","    \n","    return int(np.argmax(log_probs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"YhB67UBwokk0","outputId":"c2f0a5e4-2299-454d-9e83-47b563b949db"},"source":["# Test it out!\n","sentence_test_nxt_symbl = \"I want to fly in the sky.\"\n","detokenize([next_symbol(tokenize(sentence_test_nxt_symbl)+[0], model)])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'The'"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"markdown","metadata":{"id":"lE-oGANTokk0"},"source":["**Expected Output:**\n","```CPP\n","'The'\n","```"]},{"cell_type":"markdown","metadata":{"id":"2AwrQFglRWRj"},"source":["<a name='5.1'></a>\n","### 5.1 Greedy decoding\n","\n","Now you will implement the greedy_decode algorithm that will call the `next_symbol` function. It takes in the input_sentence, the trained model and returns the decoded sentence. \n","\n","<a name='ex07'></a>\n","### Exercise 07\n","\n","**Instructions**: Implement the greedy_decode algorithm. "]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"6HwIdimiN0k2"},"source":["# Decoding functions.\n","def greedy_decode(input_sentence, model):\n","    \"\"\"Greedy decode function.\n","\n","    Args:\n","        input_sentence (string): a sentence or article.\n","        model (trax.layers.combinators.Serial): Transformer model.\n","\n","    Returns:\n","        string: summary of the input.\n","    \"\"\"\n","    # Use tokenize()\n","    cur_output_tokens = tokenize(input_sentence) + [0]\n","    generated_output = [] \n","    cur_output = 0 \n","    EOS = 1 \n","    \n","    while cur_output != EOS:\n","        # Get next symbol\n","        cur_output = next_symbol(cur_output_tokens, model)\n","        # Append next symbol to original sentence\n","        cur_output_tokens.append(cur_output)\n","        # Append next symbol to generated sentence\n","        generated_output.append(cur_output)\n","        print(detokenize(generated_output))\n","\n","    return detokenize(generated_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"9kHuIDGW1sOr","outputId":"c86f7cc4-5e4f-4c3e-92d1-212413fc06a5"},"source":["# Test it out on a sentence!\n","test_sentence = \"It was a sunny day when I went to the market to buy some flowers. But I only found roses, not tulips.\"\n","print(wrapper.fill(test_sentence), '\\n')\n","print(greedy_decode(test_sentence, model))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["It was a sunny day when I went to the market to buy some flowers. But\n","I only found roses, not tulips. \n","\n",":\n",": I\n",": I just\n",": I just found\n",": I just found ros\n",": I just found roses\n",": I just found roses,\n",": I just found roses, not\n",": I just found roses, not tu\n",": I just found roses, not tulips\n",": I just found roses, not tulips\n",": I just found roses, not tulips.\n",": I just found roses, not tulips.<EOS>\n",": I just found roses, not tulips.<EOS>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CA-279WI2D3G"},"source":["**Expected Output:**\n","```CPP\n",":\n",": I\n",": I just\n",": I just found\n",": I just found ros\n",": I just found roses\n",": I just found roses,\n",": I just found roses, not\n",": I just found roses, not tu\n",": I just found roses, not tulips\n",": I just found roses, not tulips\n",": I just found roses, not tulips.\n",": I just found roses, not tulips.<EOS>\n",": I just found roses, not tulips.<EOS>\n","```"]},{"cell_type":"code","metadata":{"id":"DYgX-mzjyUia","scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619797787037,"user_tz":-330,"elapsed":32304,"user":{"displayName":"Sreenivas Kanaparthy","photoUrl":"","userId":"09508478944846816165"}},"outputId":"f66b44dc-fef3-4ed8-d4f0-1a7eaea1254a"},"source":["# Test it out with a whole article!\n","article = \"It’s the posing craze sweeping the U.S. after being brought to fame by skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert Pujols - and even Republican politician Rick Perry. But now four students at Riverhead High School on Long Island, New York, have been suspended for dropping to a knee and taking up a prayer pose to mimic Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were all suspended for one day because the ‘Tebowing’ craze was blocking the hallway and presenting a safety hazard to students. Scroll down for video. Banned: Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured left) were all suspended for one day by Riverhead High School on Long Island, New York, for their tribute to Broncos quarterback Tim Tebow. Issue: Four of the pupils were suspended for one day because they allegedly did not heed to warnings that the 'Tebowing' craze at the school was blocking the hallway and presenting a safety hazard to students.\"\n","print(wrapper.fill(article), '\\n')\n","print(greedy_decode(article, model))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["It’s the posing craze sweeping the U.S. after being brought to fame by\n","skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert\n","Pujols - and even Republican politician Rick Perry. But now four\n","students at Riverhead High School on Long Island, New York, have been\n","suspended for dropping to a knee and taking up a prayer pose to mimic\n","Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel,\n","Tyler Carroll and Connor Carroll were all suspended for one day\n","because the ‘Tebowing’ craze was blocking the hallway and presenting a\n","safety hazard to students. Scroll down for video. Banned: Jordan\n","Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured\n","left) were all suspended for one day by Riverhead High School on Long\n","Island, New York, for their tribute to Broncos quarterback Tim Tebow.\n","Issue: Four of the pupils were suspended for one day because they\n","allegedly did not heed to warnings that the 'Tebowing' craze at the\n","school was blocking the hallway and presenting a safety hazard to\n","students. \n","\n","Jordan\n","Jordan Ful\n","Jordan Fulcol\n","Jordan Fulcoly\n","Jordan Fulcoly,\n","Jordan Fulcoly, Wayne\n","Jordan Fulcoly, Wayne Dre\n","Jordan Fulcoly, Wayne Drexe\n","Jordan Fulcoly, Wayne Drexel\n","Jordan Fulcoly, Wayne Drexel,\n","Jordan Fulcoly, Wayne Drexel, Tyler\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day.\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not hee\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warn\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the '\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Te\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebow\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","cra\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocki\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hall\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and presenting\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and presenting a\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and presenting a safety\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and presenting a safety hazard\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and presenting a safety hazard to\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and presenting a safety hazard to\n","students\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and presenting a safety hazard to\n","students.\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and presenting a safety hazard to\n","students.<EOS>\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and presenting a safety hazard to\n","students.<EOS>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rhdO2-Dgokk2"},"source":["**Expected Output:**\n","```CPP\n","Jordan\n","Jordan Ful\n","Jordan Fulcol\n","Jordan Fulcoly\n","Jordan Fulcoly,\n","Jordan Fulcoly, Wayne\n","Jordan Fulcoly, Wayne Dre\n","Jordan Fulcoly, Wayne Drexe\n","Jordan Fulcoly, Wayne Drexel\n","Jordan Fulcoly, Wayne Drexel,\n",".\n",".\n",".\n","\n","Final summary:\n","\n","Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n","suspended for one day. Four students were suspended for one day\n","because they allegedly did not heed to warnings that the 'Tebowing'\n","craze was blocking the hallway and presenting a safety hazard to\n","students.<EOS>\n","```"]},{"cell_type":"markdown","metadata":{"id":"k_wd0Abzokk2"},"source":["**Congratulations on finishing this assignment!**"]}]}